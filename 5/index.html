<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Project 5</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="133e2de8-b697-808e-9f20-c5f8f255347b" class="page sans"><header><h1 class="page-title">Project 5</h1><p class="page-description"></p></header><div class="page-body"><h2 id="133e2de8-b697-8086-96af-cf59320f0f77" class="">By Alex Becker</h2><h1 id="133e2de8-b697-8099-b7bf-fc1bc19c7aba" class="">Part A</h1><h2 id="145e2de8-b697-800e-804e-f13dabaaa010" class="">Part 0</h2><p id="133e2de8-b697-80c0-b439-e186fd6e6952" class="">The first set of images was generated with 20 num_inference_steps</p><figure id="133e2de8-b697-80cd-b95f-d5c71f53cd03" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-03_at_12.37.03_PM.png"><img style="width:707.9765625px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-03_at_12.37.03_PM.png"/></a></figure><p id="133e2de8-b697-80bb-9bda-d21fb803e654" class="">The second set below was generated using just 10, which ran much faster. It’s interesting however because for the oil painting of the snowy mountain village, I think the one with less inference steps actually looks better overall. However, we see that there are a couple unusual things such as the very large piles of snow towards the back. The man arguably looks better with less inference steps, although the picture is in black and white, while the rocket looks pretty strange. It’s less cartoon like than the one with 20 steps, but also looks like a combination of two disfigured rockets.</p><figure id="133e2de8-b697-803d-b638-db02a1d441ef" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-03_at_12.40.54_PM.png"><img style="width:707.9921875px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-03_at_12.40.54_PM.png"/></a></figure><p id="133e2de8-b697-8032-adb5-ea22e19bc7fa" class="">
</p><p id="133e2de8-b697-80be-b6c7-f6663a9986d0" class="">
</p><h3 id="133e2de8-b697-80b4-807a-d51f196e4069" class="">Part 1: Implementing forward process</h3><p id="135e2de8-b697-807f-9577-e94024218a38" class="">For this part we implement the forward process of adding different amounts of noise to the clean source image at different time steps. Here is an example of a clean source image, as well as the image at time steps 250, 500, and 750.</p><div id="135e2de8-b697-8024-875b-d3623bbcc475" class="column-list"><div id="135e2de8-b697-8021-a45c-de31cba6ee52" style="width:25%" class="column"><figure id="135e2de8-b697-808c-aede-f17828255c82" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/clean.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/clean.png"/></a><figcaption>Clean</figcaption></figure></div><div id="135e2de8-b697-807f-99c7-f7a602c57ba1" style="width:25%" class="column"><figure id="135e2de8-b697-80ea-8acc-c14db209ebed" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/250.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/250.png"/></a><figcaption>t=250</figcaption></figure></div><div id="135e2de8-b697-80bf-b519-eb930c150ddd" style="width:25%" class="column"><figure id="135e2de8-b697-8029-8ca8-c7da0be5d9e4" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/500.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/500.png"/></a><figcaption>t=500</figcaption></figure></div><div id="135e2de8-b697-80b5-9def-d5cf45058fd1" style="width:25%" class="column"><figure id="135e2de8-b697-8092-adc2-dd438a09b422" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/750.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/750.png"/></a><figcaption>t=750</figcaption></figure></div></div><h3 id="135e2de8-b697-80fe-a62c-fbd339af9978" class="">1.2: Classical Denoising</h3><p id="135e2de8-b697-8098-8d28-fb239eff4036" class="">Before actually using a diffusion model, we will first try to denoise the test images above just by using Gaussian blurring. However, we don’t really expect this to work well, as we’re losing so much information as t gets higher and blurring cannot recover what was lost. It can really only smooth small amounts of noise. We see below that there is a tradeoff between reducing the noise and making the image too blurry, depending on how large we make the kernel. As the amount of noise increases, we have to increase the kernel size to try to smooth it, but the image becomes more blurry as a result.</p><div id="135e2de8-b697-80b5-adc0-cd7f9989ade4" class="column-list"><div id="135e2de8-b697-8003-91ec-cce89a619167" style="width:16.666666666666668%" class="column"><figure id="135e2de8-b697-802c-b6e4-c528027b3835" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/250%201.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/250%201.png"/></a><figcaption>250</figcaption></figure></div><div id="135e2de8-b697-806c-a46d-e18fe76bd134" style="width:16.666666666666668%" class="column"><figure id="135e2de8-b697-801b-b119-ca0ab19f116c" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/250-blurred.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/250-blurred.png"/></a><figcaption>kernel: 3</figcaption></figure></div><div id="135e2de8-b697-8094-a91e-fec403281e3f" style="width:16.666666666666668%" class="column"><figure id="135e2de8-b697-80c7-bcc6-c58aea8aaf23" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/500%201.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/500%201.png"/></a><figcaption>500</figcaption></figure></div><div id="135e2de8-b697-8025-8b07-f082b5b4bd12" style="width:16.666666666666668%" class="column"><figure id="135e2de8-b697-80ca-a9ca-c4cca386db69" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/500-blurred.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/500-blurred.png"/></a><figcaption>kernel: 7</figcaption></figure></div><div id="135e2de8-b697-80b7-895a-e9c82c68e784" style="width:16.666666666666668%" class="column"><figure id="135e2de8-b697-80a1-8179-e2df7eff35d7" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/750%201.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/750%201.png"/></a><figcaption>750</figcaption></figure></div><div id="135e2de8-b697-8092-b763-c2b39446c03e" style="width:16.666666666666664%" class="column"><figure id="135e2de8-b697-805d-b1c9-ec468f56d847" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/750-blurred.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/750-blurred.png"/></a><figcaption>kernel: 13</figcaption></figure></div></div><h3 id="13ae2de8-b697-8084-95cd-d89a92bd49c2" class="">1.3 One-step Denoising</h3><p id="13ae2de8-b697-80d1-8dd8-cdd8b3f24de1" class="">
</p><p id="13ae2de8-b697-8084-acb8-c35d37f2a370" class="">Now we actually use a trained unet to perform one-step denoising. Specifically, we have a unet which has been trained to denoise images, given a timestep and noisy image. The unet estimates the noise added to the original clean image at the given timestep. As we can see below, this does a much better job than the Gaussian blurring, because it at least tries to recover some of the lost information. Even if it isn’t correct, it at least looks like real images.</p><p id="13ae2de8-b697-8011-bcbd-e9043015b729" class="">
</p><div id="145e2de8-b697-8022-8a75-cb6af7b2ef3a" class="column-list"><div id="145e2de8-b697-80be-8e87-dd455527f2c5" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-8070-a6c0-ebcd231cd7ed" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image.png"/></a><figcaption>t=250</figcaption></figure></div><div id="145e2de8-b697-80ad-8aa8-cb2eedf49d65" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80be-aca3-c0acaec78c65" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%201.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%201.png"/></a><figcaption>t=500</figcaption></figure></div><div id="145e2de8-b697-8089-a98c-fd7e84ca8ecf" style="width:33.33333333333333%" class="column"><figure id="145e2de8-b697-8069-a6bc-c805faa9bbeb" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%202.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%202.png"/></a><figcaption>t=750</figcaption></figure></div></div><div id="145e2de8-b697-8097-bbc6-c5a1c54d94d9" class="column-list"><div id="145e2de8-b697-80e6-a907-d5ac80cf9e52" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80eb-8fa0-c330da17d37d" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%203.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%203.png"/></a></figure></div><div id="145e2de8-b697-8029-b4e7-c8930c9cfbff" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80b1-bd3d-d76ebcdee250" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%204.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%204.png"/></a></figure></div><div id="145e2de8-b697-8015-b1ba-dd141c08044a" style="width:33.33333333333333%" class="column"><figure id="145e2de8-b697-8051-a98e-d13034e39723" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%205.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%205.png"/></a></figure></div></div><figure id="145e2de8-b697-804b-9ae9-cb7749bc6a34" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%206.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%206.png"/></a><figcaption>clean</figcaption></figure><p id="145e2de8-b697-8058-b355-c6638cb5b448" class="">
</p><h3 id="13ae2de8-b697-80b5-9c94-ecc618d30b4c" class="">1.4 Iterative Denoising</h3><p id="144e2de8-b697-8058-a4e7-df32ee9ed3cd" class="">We can see that the Unet above did much better than the classical denoising techniques, but as we add more noise it starts to perform poorly. Now, we will implement iterative denoising. However, since our most noised image is at step t=1000, it would be too inefficient to go through every step and denoise. Fortunately, we are able to actually skip over timesteps in strides. In the example below, I started at timestep 990 and took strides of 30. I display the result at every 5th loop of denoising:</p><div id="145e2de8-b697-8069-946c-deb69ec42667" class="column-list"><div id="145e2de8-b697-80a4-92cd-d0ab62ad78d0" style="width:16.666666666666668%" class="column"><figure id="13de2de8-b697-809c-ae78-ce1dcbd99e21" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%207.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%207.png"/></a></figure></div><div id="145e2de8-b697-8059-bf85-e11baa4019e9" style="width:16.666666666666668%" class="column"><figure id="13de2de8-b697-8048-b219-e766e5085e4e" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%208.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%208.png"/></a></figure></div><div id="145e2de8-b697-80c6-acc4-eb481edd6ded" style="width:16.666666666666668%" class="column"><figure id="13de2de8-b697-8080-b6e3-cbab91207287" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%209.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%209.png"/></a></figure></div><div id="145e2de8-b697-80b3-a587-ce5d664bac2f" style="width:16.666666666666668%" class="column"><figure id="13de2de8-b697-8060-ab94-f2a30458bf20" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2010.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2010.png"/></a></figure></div><div id="145e2de8-b697-8079-9326-c006673704ee" style="width:16.666666666666668%" class="column"><figure id="13de2de8-b697-80a2-a8a3-fddfe695c5e5" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2011.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2011.png"/></a></figure></div><div id="145e2de8-b697-80ad-8f3d-e2f19a304be1" style="width:16.666666666666664%" class="column"><figure id="13de2de8-b697-801b-b96c-c550aa9671be" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2012.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2012.png"/></a></figure></div></div><p id="13de2de8-b697-8022-8032-c83015784138" class="">Below is the result of single step denoising, as well as gaussian blurring, which look much worse.</p><div id="145e2de8-b697-80b6-a45f-fa0390d4be3b" class="column-list"><div id="145e2de8-b697-802b-8d94-dfd28a2c2715" style="width:50%" class="column"><figure id="145e2de8-b697-809c-aa21-c2677c06939f" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2013.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2013.png"/></a></figure></div><div id="145e2de8-b697-80cf-b26b-cf472c63cbf9" style="width:50%" class="column"><figure id="145e2de8-b697-8008-8214-e5fe1165829e" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2014.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2014.png"/></a></figure></div></div><p id="13de2de8-b697-80ec-8037-d13516c76b6b" class="">1.5: Diffusion Model Sampling</p><p id="144e2de8-b697-8063-99ea-eedca70a94cb" class="">We can also sample by starting with random noise and iteratively denoising. For this we use the prompt “a high quality photo.” Here are 5 examples of sampling.</p><figure id="145e2de8-b697-803b-b665-e3fd72d58c42" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.00.34_PM.png"><img style="width:528px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.00.34_PM.png"/></a></figure><p id="13ee2de8-b697-8003-a298-fdb74acdd060" class="">
</p><p id="144e2de8-b697-808f-ac5d-e52cd35850f0" class="">1.6: Classifier-Free Guidance (CFG)</p><p id="145e2de8-b697-80ec-94de-fa58f8364fc6" class="">We can then use classifier free guidance to improve our image quality, as seen below. With CFG, we use both a conditional and unconditional noise estimate.</p><figure id="145e2de8-b697-808c-95c9-ff6b26e9f8de" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.02.36_PM.png"><img style="width:576px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.02.36_PM.png"/></a></figure><p id="144e2de8-b697-8024-8dd4-cc492d2f48f1" class="">
</p><p id="13ee2de8-b697-8001-a6e4-d608550d1599" class="">1.7</p><p id="13fe2de8-b697-8043-bb4e-eae9157e2c9d" class="">Using the SDEdit algorithm, we can “translate” our image by adding noise to it, and then denoising, causing our model to hallucinate something new. Below, we have 3 examples of test images, and results of this translating, starting at different noise levels. If we start at an earlier starting index, we will have more noise meaning the result will be less similar to the original.</p><div id="145e2de8-b697-8032-b89f-dab331fa8aea" class="column-list"><div id="145e2de8-b697-8004-870e-cb2283a6a68d" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-8014-918b-e0f9d1bc13bf" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2015.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2015.png"/></a></figure></div><div id="145e2de8-b697-80ae-a891-fe179f5d34de" style="width:33.33333333333333%" class="column"><figure id="145e2de8-b697-80d3-b7eb-fc63cf3945e1" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2016.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2016.png"/></a></figure></div><div id="145e2de8-b697-805a-923c-c9045a817ada" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80b7-ad6f-f7b0d5017271" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2017.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2017.png"/></a></figure></div></div><div id="145e2de8-b697-804d-9c77-e75a8ebed7f7" class="column-list"><div id="145e2de8-b697-8060-b8ae-eff08bcbb0cc" style="width:33.33333333333333%" class="column"><figure id="145e2de8-b697-80ce-b36c-d57f8a9482e4" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.06.58_PM.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.06.58_PM.png"/></a></figure></div><div id="145e2de8-b697-8047-92ee-f081c8b472c7" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80d3-966d-f2643e3531d1" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.07.09_PM.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.07.09_PM.png"/></a></figure></div><div id="145e2de8-b697-80ec-be2e-fd536e38e361" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80d0-ae3b-f4ef7a5cf008" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.07.19_PM.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.07.19_PM.png"/></a></figure></div></div><p id="13fe2de8-b697-80c0-8f41-fc31921be4f1" class=""> </p><p id="144e2de8-b697-8007-be7a-fbb0f30d580d" class="">Editing hand drawn and web images:</p><div id="145e2de8-b697-805e-9a70-d519e716c2be" class="column-list"><div id="145e2de8-b697-801b-af2c-d49c0a89a93a" style="width:50%" class="column"><figure id="145e2de8-b697-808a-b119-ead19849adda" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.12.29_PM.png"><img style="width:330.9375px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.12.29_PM.png"/></a></figure></div><div id="145e2de8-b697-80a4-99fb-fe88a9c6dfaf" style="width:50%" class="column"><figure id="145e2de8-b697-8086-b88c-f353424d9e51" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2018.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2018.png"/></a></figure></div></div><div id="145e2de8-b697-8046-af68-ca0e004821d0" class="column-list"><div id="145e2de8-b697-80ec-b61e-d8057e923e0d" style="width:50%" class="column"><figure id="145e2de8-b697-8061-a452-ddd20f65eaf7" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.13.05_PM.png"><img style="width:707.96875px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.13.05_PM.png"/></a></figure></div><div id="145e2de8-b697-8019-97be-e1f716454f1e" style="width:50%" class="column"><figure id="145e2de8-b697-8045-9278-e4e989365b01" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2019.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2019.png"/></a></figure></div></div><div id="145e2de8-b697-802f-8cfb-e2d299d8d29b" class="column-list"><div id="145e2de8-b697-80dd-b9cd-e37e87867e2c" style="width:50%" class="column"><figure id="145e2de8-b697-80c7-a08b-cbb5da5118a1" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.13.12_PM.png"><img style="width:707.96875px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.13.12_PM.png"/></a></figure></div><div id="145e2de8-b697-80b4-9b69-ec41b18313f9" style="width:50%" class="column"><figure id="145e2de8-b697-807b-9da4-fc0c7ced6b9b" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2020.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2020.png"/></a></figure></div></div><p id="145e2de8-b697-802e-932f-f766c5035acf" class="">
</p><p id="145e2de8-b697-800c-aa3a-f15486a0864a" class="">Inpainting</p><figure id="145e2de8-b697-8085-8ff7-fb5ef869cbce" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.15.10_PM.png"><img style="width:488px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.15.10_PM.png"/></a></figure><figure id="145e2de8-b697-80e9-a693-df06ee97813c" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.14.57_PM.png"><img style="width:568px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.14.57_PM.png"/></a></figure><figure id="145e2de8-b697-80f9-ab07-efc3be4e15c5" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.14.46_PM.png"><img style="width:568px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.14.46_PM.png"/></a></figure><p id="145e2de8-b697-804d-8d3c-c6f517a22a2a" class="">
</p><p id="145e2de8-b697-8031-8789-e738be2fa9ac" class="">Text-Conditional Image to image translation</p><p id="145e2de8-b697-803b-893e-d33cb9b66b98" class="">This is the same as the previous image translation, except now we use the prompt “a rocket ship”</p><div id="145e2de8-b697-80ab-8f1f-eb3091f3577a" class="column-list"><div id="145e2de8-b697-80a8-979b-dfadb72f7977" style="width:50%" class="column"><figure id="145e2de8-b697-8000-a8cd-c17b1c8bcb30" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.17.19_PM.png"><img style="width:707.953125px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.17.19_PM.png"/></a></figure></div><div id="145e2de8-b697-809c-a51f-df4795b19ada" style="width:50%" class="column"><figure id="145e2de8-b697-804d-a569-d714dcc7152a" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2021.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2021.png"/></a></figure></div></div><div id="145e2de8-b697-8095-ae23-e9cbb2a43f77" class="column-list"><div id="145e2de8-b697-80e0-9b21-e93c410720c4" style="width:50%" class="column"><figure id="145e2de8-b697-8021-8765-ced6bcf5b45a" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.17.08_PM.png"><img style="width:707.96875px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.17.08_PM.png"/></a></figure></div><div id="145e2de8-b697-802e-b2d8-f52ee6779b6b" style="width:50%" class="column"><figure id="145e2de8-b697-8016-bc2e-ebe447b6c1b4" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2022.png"><img style="width:64px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2022.png"/></a></figure></div></div><figure id="145e2de8-b697-809a-8934-e3070d385036" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.17.00_PM.png"><img style="width:432px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-20_at_9.17.00_PM.png"/></a></figure><p id="13fe2de8-b697-800c-9721-f2be5d3c0cb1" class="">1.8 Visual Anagrams</p><p id="145e2de8-b697-808d-a67d-c3d23f0632c9" class="">To create visual anagrams, during a training step, we denoise an image with one prompt, obtaining our first noise estimate. Then, we flip the image upside down and denoise with a different promp, obtaining a new noise estimate. We can flip this second estimate and average it with the first. Then we perform a denoising diffusion step on this averaged estimate. Below are 3 examples of this.</p><div id="145e2de8-b697-8077-bb88-fb2e1e123365" class="column-list"><div id="145e2de8-b697-80d5-98fa-c709f1f7d55d" style="width:50%" class="column"><figure id="145e2de8-b697-806e-aebf-ee94a86a6c7f" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2023.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2023.png"/></a><figcaption>an oil painting of people around a campfire</figcaption></figure></div><div id="145e2de8-b697-802d-853f-fbd999a32f8e" style="width:50%" class="column"><figure id="145e2de8-b697-8003-8d24-c6ec478225e5" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2024.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2024.png"/></a><figcaption>an oil painting of an old man</figcaption></figure></div></div><div id="145e2de8-b697-806f-a795-e32072ee7426" class="column-list"><div id="145e2de8-b697-8012-a4d8-e447bb3d01f8" style="width:50%" class="column"><figure id="145e2de8-b697-800b-abf4-f0b97374f4d2" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2025.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2025.png"/></a><figcaption>a photo of a city skyline at night</figcaption></figure></div><div id="145e2de8-b697-80c5-b113-c68f06c897df" style="width:50%" class="column"><figure id="145e2de8-b697-8069-b9ac-c9398ef82e57" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2026.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2026.png"/></a><figcaption>an oil painting of dark mountains</figcaption></figure></div></div><div id="145e2de8-b697-8038-abc0-cfb8604b8160" class="column-list"><div id="145e2de8-b697-809c-8640-e8a41581ab7e" style="width:50%" class="column"><figure id="145e2de8-b697-8066-bf91-cc42eb684d75" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2027.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2027.png"/></a><figcaption>a photo of galaxies</figcaption></figure></div><div id="145e2de8-b697-8084-9464-f71124ad824a" style="width:50%" class="column"><figure id="145e2de8-b697-80b3-8ce4-ffc79d27745c" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2028.png"><img style="width:144px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2028.png"/></a><figcaption>a photo of a waterfall</figcaption></figure></div></div><p id="140e2de8-b697-8028-9b0d-e86aba5773aa" class="">1.9</p><p id="145e2de8-b697-8028-abb3-cf21767aca7c" class="">We can create image hybrids similar to how we created anagrams, except instead of averaging two noise estimates, we take the high frequencies of one noise estimate and the low frequencies of another. The result is that from far away, the generated image should reflect one prompt, while close up, it should reflect the other prompt.</p><div id="145e2de8-b697-806e-b663-d7fb385d26d4" class="column-list"><div id="145e2de8-b697-8029-9033-e24814139a83" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80eb-87ee-e10558d3d43e" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2029.png"><img style="width:48px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2029.png"/></a><figcaption>a lithograph of a skull</figcaption></figure><p id="145e2de8-b697-80e4-83bc-dcc6184c3e10" class="">
</p></div><div id="145e2de8-b697-8072-89f4-e4242dba2de1" style="width:33.33333333333333%" class="column"><figure id="145e2de8-b697-80f0-9a59-db8ded054085" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2030.png"><img style="width:48px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2030.png"/></a><figcaption>a photo of a guitar</figcaption></figure><p id="145e2de8-b697-8084-bb23-fd49abf30a91" class="">
</p></div><div id="145e2de8-b697-801d-90a4-d9853c4dfb21" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-8087-b916-f3b9d1b650f5" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2031.png"><img style="width:48px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2031.png"/></a><figcaption>a lithograph of an old man</figcaption></figure><p id="145e2de8-b697-80c5-8691-f0fadeeab1f7" class="">
</p></div></div><div id="145e2de8-b697-8092-b94b-ccdd56dc611b" class="column-list"><div id="145e2de8-b697-8078-be01-f81b5d7ed670" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-807c-90bc-e19184252790" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2032.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2032.png"/></a><figcaption>a lithograph of a waterfall</figcaption></figure></div><div id="145e2de8-b697-808a-bed9-c89e763ae4ab" style="width:33.33333333333333%" class="column"><figure id="145e2de8-b697-80e7-a1c4-f907dabc3c8e" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2033.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2033.png"/></a><figcaption>a photo of a city skyline at night</figcaption></figure></div><div id="145e2de8-b697-802b-9370-e032922b0a6c" style="width:33.333333333333336%" class="column"><figure id="145e2de8-b697-80ad-881b-f1a76ad3acd2" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2034.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2034.png"/></a><figcaption>a lithograph of mountains</figcaption></figure></div></div><hr id="144e2de8-b697-80b0-9751-d8720a8a7c45"/><p id="144e2de8-b697-80cc-9dec-c72efd80e208" class="">
</p><h1 id="144e2de8-b697-80ab-808c-f76b666c21ce" class="">Part B</h1><p id="144e2de8-b697-806b-82f6-d066ef7883af" class="">In this part of the project we train our own diffusion model on the MNIST dataset</p><p id="144e2de8-b697-806f-9471-c84e248bb568" class="">
</p><h3 id="144e2de8-b697-8025-bbb0-fc166ce7d202" class="">Part 1: Single Step Denoising UNET</h3><p id="144e2de8-b697-80db-9f4b-fa99b21e0c15" class="">In this part, we first implement a UNet and train it to perform one step denoising. To train the model to be able to do this, we just add noise to training images, input these noised images into the implemented Unet, and then optimize of L2 loss of the difference between the original clean image and the resulting “denoised” image that is output by the Unet. We also choose a value sigma which scales the gaussian noise added to each pixel. Below is an example of images noised with different sigma values.</p><p id="144e2de8-b697-8092-801f-e61870e1a0ba" class="">
</p><figure id="144e2de8-b697-80cf-b160-f2abfc6d55ab" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_9.49.14_PM.png"><img style="width:428px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_9.49.14_PM.png"/></a><figcaption>sigma = 0, .2, .4, .5, .6, .8, 1</figcaption></figure><p id="144e2de8-b697-80dd-80b2-fa94816d866c" class="">
</p><figure id="144e2de8-b697-80f3-afad-cbc6a01826e1" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2035.png"><img style="width:572px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2035.png"/></a></figure><p id="144e2de8-b697-80f4-adef-dbcac85d0fdb" class="">
</p><p id="144e2de8-b697-80c4-b694-e5c33da88ff4" class="">Below are example results of our model’s denoising. The first column is original training images, then noised images, then denoised images with the model being trained for 1 epoch, then denoised images with the model being trained for 5 epochs</p><p id="144e2de8-b697-8052-8b70-f39555a0d04f" class="">
</p><div id="144e2de8-b697-8019-abed-e07657195983" class="column-list"><div id="d553d477-e903-497c-ab8f-efd9e8221e8a" style="width:25%" class="column"><figure id="2fcfe084-2112-4ca5-b832-bba37b6b8bad" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2036.png"><img style="width:84px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2036.png"/></a></figure></div><div id="01727ab7-0086-4c69-9af1-a2c65a0f1129" style="width:25%" class="column"><figure id="0dbe0a2a-dbd3-4f9f-946e-489544e65f67" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2037.png"><img style="width:72px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2037.png"/></a></figure></div><div id="26613199-dbb0-4f2b-9220-5fe7388734a6" style="width:25%" class="column"><figure id="1e09bc45-09a1-4aab-8d9d-2a39da1a7d53" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2038.png"><img style="width:84px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2038.png"/></a></figure></div><div id="02c24594-19a7-4882-8d69-f91cc8124394" style="width:25%" class="column"><figure id="e3e2456d-427f-4f26-96d8-92eedfc0eb19" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2039.png"><img style="width:84px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2039.png"/></a></figure></div></div><div id="144e2de8-b697-80d8-9896-dc2979463a01" class="column-list"><div id="9c804274-2464-4493-8420-448d1897e700" style="width:25%" class="column"><figure id="c9a5219d-6d91-4c27-9c46-455c4117953c" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2040.png"><img style="width:84px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2040.png"/></a></figure></div><div id="2f8360f4-9bd4-4f1c-ab78-ddf42c7c7f6d" style="width:25%" class="column"><figure id="6e458e12-fc0c-419e-9d20-207851589a14" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2041.png"><img style="width:84px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2041.png"/></a></figure></div><div id="1fb7f6cb-cb10-4b10-a3b5-0edaa34ac161" style="width:25%" class="column"><figure id="b735e19e-c496-4c08-8f58-5556e56c7652" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2042.png"><img style="width:96px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2042.png"/></a></figure></div><div id="0a1c3a0a-d5d7-4c25-bc12-674cbfe1b76c" style="width:25%" class="column"><figure id="a8d14cdd-dde9-43f3-b662-3d84a82a733d" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2043.png"><img style="width:96px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2043.png"/></a></figure></div></div><div id="144e2de8-b697-80b5-b5cd-c450e93e82be" class="column-list"><div id="916e74ce-bab4-41cb-bd2b-7b666bf42686" style="width:25%" class="column"><figure id="f77e68e3-7b77-4a80-b232-38dcd366cf60" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2044.png"><img style="width:96px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2044.png"/></a></figure></div><div id="2b4a65e9-3073-487e-b1ce-c8c0b671a500" style="width:25%" class="column"><figure id="e6ad4f1d-f021-4c66-b1c1-29dcdfd22930" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2045.png"><img style="width:96px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2045.png"/></a></figure></div><div id="72fe58b8-a9fe-4a5c-aef0-2aa8a90bdf25" style="width:25%" class="column"><figure id="4a5c9ca3-2ea5-491f-8c57-03766ed709fa" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2046.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2046.png"/></a></figure></div><div id="729acc00-b206-4439-a325-3cef050b8896" style="width:25%" class="column"><figure id="47ee93c5-6545-4098-8ab9-ca2674ce61d6" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2047.png"><img style="width:108px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2047.png"/></a></figure></div></div><p id="144e2de8-b697-8020-95fb-dc59eb3d0feb" class="">
</p><p id="144e2de8-b697-809e-ae1e-cccf567dcf58" class="">While we trained our model with a sigma value of .5, we can also see how it works for other values of sigma. As we would expect, it doesn’t work as well as sigma gets very high. The sigma values used are the same as mentioned above.</p><div id="144e2de8-b697-80b9-a14d-c76b89bf9e4c" class="column-list"><div id="144e2de8-b697-802a-aff0-e0aff462c40f" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-80be-89dc-e51c7f967e3a" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2048.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2048.png"/></a></figure></div><div id="144e2de8-b697-80bb-9b72-d39ca908c47c" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-800d-8220-d006a7188ba3" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2049.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2049.png"/></a></figure></div><div id="144e2de8-b697-8012-b336-e8029fa0974e" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-809b-a4da-d9b8e71198e7" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2050.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2050.png"/></a></figure></div><div id="144e2de8-b697-8085-a23e-f988a5ffdca6" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-8077-aab9-f761378dddc3" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2051.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2051.png"/></a></figure></div><div id="144e2de8-b697-8095-8cb7-e75fd5cf70dd" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-80cc-9459-cdabeebe9d94" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2052.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2052.png"/></a></figure></div><div id="144e2de8-b697-8066-87f3-da4486be900a" style="width:14.285714285714285%" class="column"><figure id="144e2de8-b697-80dc-8eb6-ea4b100a6647" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2053.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2053.png"/></a></figure></div><div id="144e2de8-b697-807c-898d-efb4b4c8ae0a" style="width:14.285714285714285%" class="column"><figure id="144e2de8-b697-80d2-9ef9-cf36848bcc51" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2054.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2054.png"/></a></figure></div></div><div id="144e2de8-b697-800f-ba60-ee4c71d027b3" class="column-list"><div id="144e2de8-b697-8097-8250-ed06a80a7086" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-804e-94c6-e89974f5bbc9" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2055.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2055.png"/></a></figure></div><div id="144e2de8-b697-806d-ab0e-e3f1511a19e2" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-803d-9e6b-d969fcc9dd18" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2056.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2056.png"/></a></figure></div><div id="144e2de8-b697-80f0-bbce-f5a938122b02" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-8046-9816-d56c907b3783" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2057.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2057.png"/></a></figure></div><div id="144e2de8-b697-808a-8667-ca5fa88ca5d9" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-80f2-a93f-ef7a426776a6" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2058.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2058.png"/></a></figure></div><div id="144e2de8-b697-808f-b3a1-cd7c954bcc94" style="width:14.285714285714288%" class="column"><figure id="144e2de8-b697-80d7-bb6d-cb7223b5446b" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2059.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2059.png"/></a></figure></div><div id="144e2de8-b697-8032-9619-ebffc286100b" style="width:14.285714285714285%" class="column"><figure id="144e2de8-b697-8002-8f5a-d1394e9e99ab" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2060.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2060.png"/></a></figure></div><div id="144e2de8-b697-8052-8f38-f34aa6a3dbec" style="width:14.285714285714285%" class="column"><figure id="144e2de8-b697-806f-a603-fbf915f01767" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2061.png"><img style="width:28px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2061.png"/></a></figure></div></div><p id="144e2de8-b697-80ca-8097-df89200d1c63" class="">
</p><h3 id="144e2de8-b697-80a6-a71c-ea56b4454144" class="">Part 2: Training a Diffusion Model</h3><p id="144e2de8-b697-8024-a3dc-df4b3541fced" class="">Now, we implement the DDMP paper to use our UNet to iteratively denoise an image. For this step, we make one small change to the model: Before, we were minimizing the loss between the original clean image and our denoised image, while now we minimize the loss between the added noise and the predicted noise. Because we now want to iteratively denoise, we need to somehow condition the model on the timestep of a noised image, meaning how far along the process of denoising it is. To do this we had to add two more components to the UNet architecture, which use fully connected layers to inject time values into the model, so that our model can be conditioned to time.</p><p id="144e2de8-b697-803f-a927-c63b4c4087a5" class="">
</p><p id="144e2de8-b697-8016-ba6e-fe95bb2ee3a8" class="">Now, to train this model, we just have to choose a training image, sample a random t value, and then pass these in to our model. We then repeat this many times and optimize over the L2 loss as explained previously.</p><p id="144e2de8-b697-809d-83f0-e596775e6e39" class="">
</p><figure id="144e2de8-b697-80e3-b727-d10e728743bd" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2062.png"><img style="width:567px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2062.png"/></a></figure><p id="144e2de8-b697-80a7-9eb0-e35ffc8e43ea" class="">
</p><p id="144e2de8-b697-80cf-9411-c3dab68c0f00" class="">We can also sample from our model now by iteratively denoising generated pure noise. Below are some results of this. </p><p id="144e2de8-b697-8089-8fcb-e6a61aa29e7f" class="">
</p><figure id="144e2de8-b697-80f6-b73a-db47d5be7e0c" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.28.56_PM.png"><img style="width:610px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.28.56_PM.png"/></a><figcaption>Sampled after 5 epochs</figcaption></figure><p id="144e2de8-b697-805e-af45-d198ef7e476a" class="">
</p><figure id="144e2de8-b697-805b-b384-c2aac106148c" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.28.51_PM.png"><img style="width:612px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.28.51_PM.png"/></a><figcaption>Sampled after 20 epochs</figcaption></figure><p id="144e2de8-b697-80c3-a7d9-e14a534f68c6" class="">
</p><p id="144e2de8-b697-8015-933b-c306b57f9dab" class="">We can see that while some of the sampled images above look pretty, good, many of them don’t look like actual numbers. To improve this, we can also introduce class conditioning, similar to how we previously introduced time conditioning. We just have to add two more fully connected blocks, which this time inject a one-hot encoded vector of a digit class (1-9). This way, when training the model, we can use the label of each training image to create these vectors and inject them into the model. This results in the model being able to be conditioned on class.</p><p id="144e2de8-b697-807b-88f7-c853ea43af44" class="">
</p><figure id="144e2de8-b697-803d-8539-f7c7a054760f" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2063.png"><img style="width:567px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/image%2063.png"/></a></figure><p id="144e2de8-b697-808b-a36d-ff550adebc50" class="">
</p><p id="144e2de8-b697-809b-8d17-d129c30689a6" class="">Below are examples of sampling images using this class conditioning</p><figure id="144e2de8-b697-8064-823a-c4c55160edf1" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.33.55_PM.png"><img style="width:610px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.33.55_PM.png"/></a><figcaption>Sampling after 5 epochs</figcaption></figure><p id="144e2de8-b697-804f-8295-f0098609959b" class="">
</p><figure id="144e2de8-b697-80a0-a17f-f2ae5b9e42dc" class="image"><a href="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.33.51_PM.png"><img style="width:608px" src="Project%205%20133e2de8b697808e9f20c5f8f255347b/Screenshot_2024-11-19_at_10.33.51_PM.png"/></a><figcaption>Sampling after 20 epochs</figcaption></figure></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>